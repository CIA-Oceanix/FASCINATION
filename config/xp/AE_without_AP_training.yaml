# @package _global_

paths:
    sound: /DATASET/eNATL/eNATL60_BLB002_sound_speed_regrid_0_1000m.nc
    accoustic: /DATASET/envs/o23gauvr/tmp/eNATL60_BLB002_ECS_at_0_regrid_0_1000m.nc
    acc_model_path: /homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/accoustic_predictor_50/dense_2D_CNN_ReLu/pred_weight_1_classif_weight_0_2024-05-18_13-25/checkpoints/val_loss=0.02-epoch=46.ckpt

normalization:
  x_min: 1459.0439165829073
  x_max: 1545.8698054910844

trainer:
  _target_: pytorch_lightning.Trainer
  inference_mode: False
  accelerator: gpu
  devices: 1
  check_val_every_n_epoch: 1
  logger: 
    #_target_: pytorch_lightning.loggers.CSVLogger
    _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    #save_dir: ${hydra:runtime.output_dir}
    save_dir: /homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE_without_AP/
    #name: ${hydra:runtime.choices.xp}
    name: ${model.arch_shape}
    version: ${now:%Y-%m-%d_%H-%M}
    # sub_dir: ${model.final_act_func}_lr_${model.lr}
  min_epochs: 0
  max_epochs: 1000
  callbacks:
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_loss
      save_top_k: 1
      filename: '{val_loss:.2f}-{epoch:02d}'
      mode: min
    - _target_: pytorch_lightning.callbacks.EarlyStopping
      monitor: val_loss
      min_delta: 0.
      check_on_train_epoch_end: True
      patience: 5
      verbose: True


# datamodule:
#   _target_: src.data.AutoEncoderDatamodule
#   input_da: 
#     _target_: src.utils.load_sound_speed_fields
#     path: ${paths.sound}
#   domains:
#     train:
#       time: {_target_: builtins.slice, _args_: [0, 254]}
#     val: 
#       time: {_target_: builtins.slice, _args_: [254, 331]}
#     test: 
#       time: {_target_: builtins.slice,  _args_: [331, 365]}
#   dl_kw: {batch_size: 4, num_workers: 4}
#   x_min: ${normalization.x_min}
#   x_max: ${normalization.x_max}
#   pickle_path: ${trainer.logger.save_dir}/${trainer.logger.name}/${trainer.logger.version}/pickle/time_idx_per_split.pickle

datamodule:
  _target_: src.data.BaseDatamodule
  input_da: 
    _target_: src.utils.load_ssf_ecs_da
    ssf_da_path: ${paths.sound}
    ecs_da_path: ${paths.accoustic}
  dl_kw: {batch_size: 4, num_workers: 4}
  x_min: ${normalization.x_min}
  x_max: ${normalization.x_max}




model:
  _target_: src.autoencoder.AutoEncoder
  x_min: ${normalization.x_min}
  x_max: ${normalization.x_max}
  lr: 0.001
  arch_shape: '20_60_dense_avgpool_upsample_final_Relu'
  final_act_func: sigmoid  #sigmoid, relu
  acoustic_predictor:
    _target_: src.acoustic_predictor.AcousticPredictor.load_from_checkpoint
    checkpoint_path: ${paths.acc_model_path}
    # hparams_file:
    #   _target_: src.utils.get_ap_config_file_path_from_ckpt_path
    #   ap_ckpt_path: ${paths.acc_model_path}

    
    input_depth: 107
    arch_shape: 
      _target_: src.utils.get_ap_arch_shape_from_ckpt
      ap_ckpt_path: ${paths.acc_model_path}

  accoustic_training: False


hydra:
  run:
    dir: ${trainer.logger.save_dir}/${trainer.logger.name}/${trainer.logger.version}

entrypoints:
  - _target_: pytorch_lightning.seed_everything
    seed: 333
  - _target_: src.train.base_training
    trainer: ${trainer}
    lit_mod: ${model}
    dm: ${datamodule}
    pickle_path: ${trainer.logger.save_dir}/${trainer.logger.name}/${trainer.logger.version}/pickle/time_idx_per_split.pickle



