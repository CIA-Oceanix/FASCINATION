# @package _global_

paths:
    sound: /DATASET/eNATL/eNATL60_BLB002_sound_speed_regrid_0_1000m.nc
    variables: /DATASET/envs/o23gauvr/tmp/eNATL60_BLB002_ECS_at_0_regrid_0_1000m.nc

normalization:
  x_min: 1459.0439165829073
  x_max: 1545.8698054910844

dtype: float32 #float16 #float64 


model_architecture: ECS_explicit_pred # CNN #CNN_with_classif #Dense_CNN_with_classif #CNN #Dense_CNN 

dimensions: 3D  #2D #3D



trainer:
  _target_: pytorch_lightning.Trainer
  inference_mode: False
  accelerator: gpu
  devices: 1
  check_val_every_n_epoch: 1
  accumulate_grad_batches: ${model_config.accumulate_grad_batches.${dimensions}}
  logger: 
    _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    save_dir: /homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/accoustic_predictor_V2/
    name: ${model.model_name}
    version: ${now:%Y-%m-%d_%H-%M}
    #version: pred_weight_${model.pred_weight}_classif_weight_${model.classif_weight}_${now:%Y-%m-%d_%H-%M}

  min_epochs: 0
  max_epochs: 1
  callbacks:
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_loss
      save_top_k: 1
      filename: '{val_loss:.2f}-{epoch:02d}'
      mode: min
    - _target_: pytorch_lightning.callbacks.EarlyStopping
      monitor: val_loss
      min_delta: 0.
      check_on_train_epoch_end: True
      verbose: True
      patience: 5

      

datamodule:
  _target_: src.data.BaseDatamodule
  input_da: 
    _target_: src.utils.load_ssf_ecs_da
    ssf_da_path: ${paths.sound}
    ecs_da_path: ${paths.variables}
  dl_kw:
    batch_size: ${model_config.batch_size.${dimensions}}
    num_workers: 4
  x_min: ${normalization.x_min}
  x_max: ${normalization.x_max}
  dtype_str: ${dtype}  



model:
  _target_: src.acoustic_predictor_V2.AcousticPredictor
  model_name: ${model_architecture}_${dimensions}
  model_hparams: ${model_config.model_hparams.${model.model_name}}
  opt_fn:
    _target_: src.ecs_classification.ECS_classification.cosanneal_lr_adamw
    _partial_: true
    lr: 1e-3
    T_max: ${trainer.max_epochs}
    weight_decay: 1e-2
  ecs_classif_ckpt_path: /homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/ap_classif/UNet_2D/2024-05-30_16-59/checkpoints/val_loss=0.36-epoch=18.ckpt
  loss_weight:
    pred_weight: 1
    classif_weight: 1
  mask_type: None
  loss_name: DiceBCELoss
  loss_hparams: ${model_config.loss_hparams.${model.loss_name}}




model_config:
  model_hparams:
    Dense_CNN_2D:
      num_layers: 4
      input_depth: 107
      acoustic_variables: 1
      dtype_str: ${dtype}

    CNN_with_classif_3D:
      num_classes_pred: 1
      num_classes_classif: 2
      in_ch: 3
      channels_start: 20
      num_layers: 4
      batch_norm: True
      avg_pool: False
      dtype_str: ${dtype}
      spatial_dim: [240, 240] 
      loss_weight:
        no_ecs_weight: 1
        ecs_weight: 10


    CNN_3D: &CNNDefaults
      num_classes: 1
      in_ch: 3
      channels_start: 20
      num_layers: 4
      batch_norm: True
      avg_pool: False
      dtype_str: ${dtype}
      final_act_func: Sigmoid
      spatial_dim: [240, 240]

    CNN_2D: 
      <<: *CNNDefaults
      in_ch: 107

      
    ECS_explicit_pred_3D: 
      depth_array:
        _target_: src.utils.get_depth_array
        ssf_da_path: ${paths.sound}


  batch_size:
    2D: 4
    3D: 1

  accumulate_grad_batches:
    2D: 1
    3D: 4


  loss_hparams:
    BCELoss:
      weight: ${model_config.BCELoss_weight}
      reduction: mean

    DiceLoss:
      epsilon: 1

    DiceBCELoss:
      epsilon: 1
      weight: ${model_config.BCELoss_weight}
      reduction: mean

  BCELoss_weight: .5



entrypoints:
  - _target_: pytorch_lightning.seed_everything
    seed: 333
  - _target_: src.train.base_training
    trainer: ${trainer}
    lit_mod: ${model}
    dm: ${datamodule}


hydra:
  run:
    dir: ${trainer.logger.save_dir}/${trainer.logger.name}/${trainer.logger.version}
  job:
    env_set: 
      CUDA_VISIBLE_DEVICES: 1

# torch:
#   backends:
#     cudnn:
#       allow_tf32: False