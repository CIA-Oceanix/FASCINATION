{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import hydra\n",
    "import glob\n",
    "import pickle\n",
    "from src.utils import get_cfg_from_from_ckpt_path\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from src.utils import *\n",
    "from src.model.autoencoder.AE_CNN_3D import AE_CNN_3D\n",
    "from src.model.autoencoder.AE_CNN_1D import AE_CNN_1D\n",
    "from src.explicit_ecs import ECS_explicit_pred_1D, ECS_explicit_pred_3D\n",
    "\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 2\n",
    "    \n",
    "if torch.cuda.is_available() and gpu is not None:\n",
    "##This may not be necessary outside the notebook\n",
    "    dev = f\"cuda:{gpu}\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_ckpt_path: str,\n",
    "               device: str):\n",
    "\n",
    "    cfg = get_cfg_from_from_ckpt_path(model_ckpt_path, pprint = False)\n",
    "    \n",
    "    lit_mod = hydra.utils.call(cfg.model)\n",
    "\n",
    "    lit_mod.load_state_dict(torch.load(model_ckpt_path)[\"state_dict\"])\n",
    "\n",
    "\n",
    "    lit_mod = lit_mod.to(device) # Move model to gpu for faster inference\n",
    "    lit_mod = lit_mod.eval() # Model in eval mode\n",
    "    for param in lit_mod.parameters():\n",
    "        param.requires_grad = False  # Ensure no gradients are calculated for this model\n",
    "\n",
    "    return lit_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssf_da_path = \"/DATASET/eNATL/eNATL60_BLB002_sound_speed_regrid_0_1000m.nc\"\n",
    "ssp_da = xr.open_dataarray(ssf_da_path).dropna(dim=\"lat\")\n",
    "\n",
    "coords = ssp_da.coords\n",
    "depth_array = coords['z'].data\n",
    "\n",
    "\n",
    "ssp_arr = ssp_da.data.transpose(0,2,3,1)\n",
    "ssp_shape = ssp_arr.shape\n",
    "#ssp_arr_flatten = np.flatten(ssp_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE_V2/AE_CNN_3D/pred_1_grad_0/channels_list_[1, 1]_1_conv_per_layer_padding_linear_pooling_None_final_upsample_upsample_pooling/act_fn_None_final_act_fn_None_normalization_min_max/manage_nan_suppress/n_profiles_None/lr_0.1/2024-09-09_20-31/checkpoints/val_loss=0.00-epoch=883.ckpt\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"/homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE_V2/AE_CNN_3D/pred_1_grad_0/channels_list_[1, 1]_1_conv_per_layer_padding_linear_pooling_None_final_upsample_upsample_pooling/act_fn_None_final_act_fn_None_normalization_min_max/manage_nan_suppress/n_profiles_None/lr_0.1/2024-09-09_20-31/checkpoints/val_loss=0.00-epoch=883.ckpt\"\n",
    "print(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```yaml\n",
       "\n",
       "datamodule:\n",
       "  _target_: src.autoencoder_datamodule.AutoEncoderDatamodule_${dimensions}\n",
       "  dl_kw: {batch_size: '${model_config.batch_size.${dimensions}}', num_workers: 4}\n",
       "  dtype_str: ${dtype}\n",
       "  input_da: {_target_: src.utils.load_ssp_da, ssf_da_path: '${paths.sound}'}\n",
       "  manage_nan: suppress\n",
       "  n_profiles: null\n",
       "  norm_stats: {method: min_max, params: '${normalization.${datamodule.norm_stats.method}}'}\n",
       "dimensions: 3D\n",
       "dtype: float32\n",
       "entrypoints:\n",
       "- {_target_: pytorch_lightning.seed_everything, seed: 333}\n",
       "- {_target_: src.train.base_training, dim: '${dimensions}', dm: '${datamodule}', lit_mod: '${model}',\n",
       "  trainer: '${trainer}'}\n",
       "model:\n",
       "  _target_: src.autoencoder_V2.AutoEncoder\n",
       "  depth_array: {_target_: src.utils.get_depth_array, ssf_da_path: '${paths.sound}'}\n",
       "  dim: ${dimensions}\n",
       "  loss_weight: {ecs_weight: 0, gradient_weight: 0, max_position_weight: 0, prediction_weight: 1,\n",
       "    variation_weight: 0}\n",
       "  model_hparams: ${model_config.model_hparams.${model.model_name}}\n",
       "  model_name: ${model_architecture}_${dimensions}\n",
       "  opt_fn: {T_max: 100000, _partial_: true, _target_: src.ecs_classification.ECS_classification.cosanneal_lr_adamw,\n",
       "    lr: 0.1, weight_decay: 0}\n",
       "model_architecture: AE_CNN\n",
       "model_config:\n",
       "  accumulate_grad_batches: {1D: 1, 2D: 1, 3D: 1}\n",
       "  batch_size: {1D: 512, 2D: 32, 3D: 4}\n",
       "  model_hparams:\n",
       "    AE_CNN_1D:\n",
       "      act_fn_str: None\n",
       "      channels_list: [1, 1]\n",
       "      dropout_proba: 0\n",
       "      dtype_str: ${dtype}\n",
       "      final_act_fn_str: None\n",
       "      final_upsample_str: upsample_pooling\n",
       "      latent_size: 9\n",
       "      linear_layer: false\n",
       "      n_conv_per_layer: 1\n",
       "      padding: linear\n",
       "      pooling: None\n",
       "    AE_CNN_2D:\n",
       "      act_fn_str: None\n",
       "      channels_list: [1, 1]\n",
       "      dropout_proba: 0\n",
       "      dtype_str: ${dtype}\n",
       "      final_act_fn_str: None\n",
       "      final_upsample_str: upsample_pooling\n",
       "      latent_size: 100\n",
       "      linear_layer: false\n",
       "      n_conv_per_layer: 1\n",
       "      padding: linear\n",
       "      pooling: None\n",
       "    AE_CNN_3D:\n",
       "      act_fn_str: None\n",
       "      channels_list: [1, 1]\n",
       "      dropout_proba: 0\n",
       "      dtype_str: ${dtype}\n",
       "      final_act_fn_str: None\n",
       "      final_upsample_str: upsample_pooling\n",
       "      latent_size: 100\n",
       "      linear_layer: false\n",
       "      n_conv_per_layer: 1\n",
       "      padding: linear\n",
       "      pooling: None\n",
       "    AE_CNN_pool_2D:\n",
       "      act_fn_str: Sigmoid\n",
       "      dropout_proba: 0\n",
       "      dtype_str: float32\n",
       "      final_act_fn_str: Relu\n",
       "      init_params:\n",
       "        params: {_target_: src.utils.get_convo_init_weight_bias, init_params_pickle_path: \"/homes/o23gauvr/Documents/th\\xE8\\\n",
       "            se/code/FASCINATION/pickle/pca_mean_and_components.pkl\"}\n",
       "        use: false\n",
       "      input_channels: 107\n",
       "      latent_dim: 9\n",
       "      num_layers: 1\n",
       "      pooling_str: Max\n",
       "  save_dir: {AE_CNN: 'channels_list_${model.model_hparams.channels_list}_${model.model_hparams.n_conv_per_layer}_conv_per_layer_padding_${model.model_hparams.padding}_pooling_${model.model_hparams.pooling}_final_upsample_${model.model_hparams.final_upsample_str}/act_fn_${model.model_hparams.act_fn_str}_final_act_fn_${model.model_hparams.final_act_fn_str}_normalization_${datamodule.norm_stats.method}',\n",
       "    AE_CNN_pool_1D: 'latent_dim_${model.model_hparams.latent_dim}_pooling_${model.model_hparams.num_layers}_${model.model_hparams.pooling_str}_dropout_${model.model_hparams.dropout_proba}_patience_${patience}',\n",
       "    AE_CNN_pool_2D: 'latent_dim_${model.model_hparams.latent_dim}_pooling_${model.model_hparams.num_layers}_${model.model_hparams.pooling_str}_dropout_${model.model_hparams.dropout_proba}_patience_${patience}/act_fn_${model.model_hparams.act_fn_str}_final_act_fn_${model.model_hparams.final_act_fn_str}_normalization_${datamodule.norm_stats.method}'}\n",
       "normalization:\n",
       "  mean_std: {mean: null, std: null}\n",
       "  mean_std_along_depth: {mean: null, std: null}\n",
       "  min_max: {x_max: null, x_min: null}\n",
       "paths: {sound: /DATASET/eNATL/eNATL60_BLB002_sound_speed_regrid_0_1000m.nc}\n",
       "patience: 25\n",
       "trainer:\n",
       "  _target_: pytorch_lightning.Trainer\n",
       "  accelerator: gpu\n",
       "  accumulate_grad_batches: ${model_config.accumulate_grad_batches.${dimensions}}\n",
       "  callbacks:\n",
       "  - {_target_: pytorch_lightning.callbacks.LearningRateMonitor}\n",
       "  - {_target_: pytorch_lightning.callbacks.ModelCheckpoint, filename: '{val_loss:.2f}-{epoch:02d}',\n",
       "    mode: min, monitor: val_loss, save_top_k: 1}\n",
       "  - {_target_: pytorch_lightning.callbacks.EarlyStopping, check_on_train_epoch_end: true,\n",
       "    min_delta: 0.0, monitor: val_loss, patience: '${trainer.max_epochs}', verbose: true}\n",
       "  check_val_every_n_epoch: 1\n",
       "  devices: 1\n",
       "  inference_mode: false\n",
       "  logger: {_target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger, log_graph: false,\n",
       "    name: '${model.model_name}/pred_${model.loss_weight.prediction_weight}_grad_${model.loss_weight.gradient_weight}',\n",
       "    save_dir: \"/homes/o23gauvr/Documents/th\\xE8se/code/FASCINATION/outputs/AE_V2/\",\n",
       "    version: '${model_config.save_dir.${model_architecture}}/manage_nan_${datamodule.manage_nan}/n_profiles_${datamodule.n_profiles}/lr_${model.opt_fn.lr}/${now:%Y-%m-%d_%H-%M}'}\n",
       "  max_epochs: 2000\n",
       "  min_epochs: 0\n",
       "\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = get_cfg_from_from_ckpt_path(ckpt_path, pprint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = load_model(ckpt_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = hydra.utils.call(cfg.datamodule) # will instantiate src.data.BaseDataModule with parameters specified in config\n",
    "dm.setup(stage=\"fit\") # setup the datamodule see https://lightning.ai/docs/pytorch/stable/data/datamodule.html#lightningdatamodule-api\n",
    "dm.setup(stage=\"test\") # setup the datamodule see https://lightning.ai/docs/pytorch/stable/data/datamodule.html#lightningdatamodule-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ssp_arr = dm.train_dataloader().dataset.input.data\n",
    "train_ssp_tens = torch.tensor(train_ssp_arr).float().to(device)\n",
    "input_train_shape = train_ssp_arr.shape\n",
    "\n",
    "test_ssp_arr = dm.test_dataloader().dataset.input.data\n",
    "test_ssp_tens = torch.tensor(test_ssp_arr).float().to(device)\n",
    "input_test_shape = test_ssp_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = []\n",
    "for ssp_truth in (dm.train_dataloader()):\n",
    "    ssp_truth = ssp_truth.to(lit_model.device) \n",
    "    ssp_pred = lit_model(ssp_truth.to(lit_model.device))\n",
    "    mse.append(torch.mean((ssp_truth-ssp_pred)**2).item())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31574134e-05, 1.32356190e-05, 1.32518153e-05, 1.34056017e-05,\n",
       "       1.36985464e-05, 1.37362968e-05, 1.37428615e-05, 1.39450131e-05,\n",
       "       1.39596823e-05, 1.40508910e-05, 1.41116461e-05, 1.41176024e-05,\n",
       "       1.41349055e-05, 1.42970939e-05, 1.43207317e-05, 1.43642810e-05,\n",
       "       1.44026335e-05, 1.44498335e-05, 1.45986069e-05, 1.47260980e-05,\n",
       "       1.47356695e-05, 1.47371420e-05, 1.47570163e-05, 1.47587207e-05,\n",
       "       1.48349372e-05, 1.48664067e-05, 1.49224943e-05, 1.50545447e-05,\n",
       "       1.51686654e-05, 1.52205248e-05, 1.52324446e-05, 1.53139717e-05,\n",
       "       1.53965520e-05, 1.54155659e-05, 1.54283061e-05, 1.54893460e-05,\n",
       "       1.55171547e-05, 1.55327052e-05, 1.55919515e-05, 1.56767837e-05,\n",
       "       1.57195755e-05, 1.57619379e-05, 1.59694955e-05, 1.60573090e-05,\n",
       "       1.60773689e-05, 1.61378375e-05, 1.62164251e-05, 1.62694341e-05,\n",
       "       1.65364454e-05, 1.65841084e-05, 1.65953916e-05, 1.66125647e-05,\n",
       "       1.66314876e-05, 1.67130329e-05, 1.67509697e-05, 1.68021652e-05,\n",
       "       1.68713086e-05, 1.69424184e-05, 1.69882969e-05, 1.70569419e-05,\n",
       "       1.71100146e-05, 1.76842859e-05, 1.81855285e-05, 1.91548806e-05])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9154880646965466e-05"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"[1,1]_trilinear_test_on_padding\" in \"/homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE/AE_CNN_3D/[1,1]_trilinear_test_on_padding/pred_1_grad_0/upsample_mode_trilinear/1_conv_per_layer/padding_linear/pooling_Max_on_dim_all/final_upsample_upsample_pooling/act_fn_None_final_act_fn_None/lr_0.001/normalization_min_max/manage_nan_suppress/n_profiles_None/2024-10-10_15-00/checkpoints/val_loss=0.00-epoch=555.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE/AE_CNN_3D/channels_[1, 1]/pred_1_grad_0/channels_list_[1, 1]_1_conv_per_layer_padding_linear_pooling_Max_on_dim_all_final_upsample_upsample_pooling/act_fn_None_final_act_fn_Sigmoid_normalization_min_max/manage_nan_suppress/n_profiles_None/lr_0.0001/2024-09-23_13-40/checkpoints/val_loss=0.00-epoch=182.ckpt')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:00<00:00, 246554.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE/AE_CNN_3D/upsample_mode_test_on_[1,1]/pred_1_grad_0/upsample_mode_trilinear/1_conv_per_layer/padding_linear/pooling_Max_on_dim_all/final_upsample_upsample_pooling/act_fn_None_final_act_fn_None/lr_0.001/normalization_min_max/manage_nan_suppress/n_profiles_None/2024-10-09_17-00/checkpoints/val_loss=0.00-epoch=783.ckpt because it contains a directory to ignore.\n",
      "Skipping /homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE/AE_CNN_3D/upsample_mode_test_on_[1,1]/pred_1_grad_0/upsample_mode_area/1_conv_per_layer/padding_linear/pooling_Max_on_dim_all/final_upsample_upsample_pooling/act_fn_None_final_act_fn_None/lr_0.001/normalization_min_max/manage_nan_suppress/n_profiles_None/2024-10-10_14-23/checkpoints/val_loss=0.00-epoch=661.ckpt because it contains a directory to ignore.\n",
      "Skipping /homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE/AE_CNN_3D/[1,1]_trilinear_test_on_padding/pred_1_grad_0/upsample_mode_trilinear/1_conv_per_layer/padding_linear/pooling_Max_on_dim_all/final_upsample_upsample_pooling/act_fn_None_final_act_fn_None/lr_0.001/normalization_min_max/manage_nan_suppress/n_profiles_None/2024-10-10_15-00/checkpoints/val_loss=0.00-epoch=556.ckpt because it contains a directory to ignore.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = \"/homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs\"\n",
    "\n",
    "dir_to_ignore = [\"[1,1]_trilinear_test_on_padding\", \"upsample_mode_test_on_[1,1]\"]\n",
    "\n",
    "ckpt_list = list(Path(output_path).rglob('*.ckpt'))\n",
    "\n",
    "for ckpt_path in tqdm(ckpt_list):\n",
    "    \n",
    "    ckpt_path = str(ckpt_path)\n",
    "    \n",
    "    if any(dir_name in ckpt_path for dir_name in dir_to_ignore):\n",
    "        print(f\"Skipping {ckpt_path} because it contains a directory to ignore.\")\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg_from_from_ckpt_path(str(ckpt_path), pprint = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "channels_${model.model_hparams.channels_list}/pred_${model.loss_weight.prediction_weight}_grad_${model.loss_weight.gradient_weight}/${model.model_hparams.n_conv_per_layer}_conv_per_layer/padding_${model.model_hparams.padding}/pooling_${model.model_hparams.pooling}_on_dim_${model.model_hparams.pooling_dim}/final_upsample_${model.model_hparams.final_upsample_str}/act_fn_${model.model_hparams.act_fn_str}_final_act_fn_${model.model_hparams.final_act_fn_str}/lr_${model.opt_fn.lr}/normalization_${datamodule.norm_stats.method}/manage_nan_${datamodule.manage_nan}/n_profiles_${datamodule.n_profiles}/${now:%Y-%m-%d_%H-%M}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (2721036059.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[56], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    dest_dir =  f\"{cfg[\"trainer\"][\"logger\"][\"save_dir\"].split(\"AE\")[0]}AE/\" \\\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dest_dir =  f\"{cfg[\"trainer\"][\"logger\"][\"save_dir\"].split(\"AE\")[0]}AE/\" \\\n",
    "            f\"{cfg['model']['model_name']}\" \\\n",
    "            f\"channels_{channels_list}/pred_{prediction_weight}_grad_{gradient_weight}/\" \\\n",
    "            f\"{n_conv_per_layer}_conv_per_layer/padding_{padding}/pooling_{pooling}_on_dim_{pooling_dim}/\" \\\n",
    "            f\"final_upsample_{final_upsample_str}/act_fn_{act_fn_str}_final_act_fn_{final_act_fn_str}/\" \\\n",
    "            f\"lr_{lr}/normalization_{normalization_method}/manage_nan_{manage_nan}/n_profiles_{n_profiles}/{date}\"\n",
    "dest_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE/ ${model.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = cfg[\"trainer\"][\"logger\"][\"save_dir\"].split(\"AE\")[0]\n",
    "model_name = cfg['model']['model_name']\n",
    "\n",
    "channels_list = str(cfg['model_config']['model_hparams']['AE_CNN_3D']['channels_list'])\n",
    "prediction_weight = cfg['model']['loss_weight']['prediction_weight']\n",
    "gradient_weight = cfg['model']['loss_weight']['gradient_weight']\n",
    "n_conv_per_layer = cfg['model_config']['model_hparams']['AE_CNN_3D']['n_conv_per_layer']\n",
    "padding = cfg['model_config']['model_hparams']['AE_CNN_3D']['padding']\n",
    "pooling = cfg['model_config']['model_hparams']['AE_CNN_3D']['pooling']\n",
    "pooling_dim = cfg['model_config']['model_hparams']['AE_CNN_3D']['pooling_dim']\n",
    "final_upsample_str = cfg['model_config']['model_hparams']['AE_CNN_3D']['final_upsample_str']\n",
    "act_fn_str = cfg['model_config']['model_hparams']['AE_CNN_3D']['act_fn_str']\n",
    "final_act_fn_str = cfg['model_config']['model_hparams']['AE_CNN_3D']['final_act_fn_str']\n",
    "lr = cfg['model']['opt_fn']['lr']\n",
    "normalization_method = cfg['datamodule']['norm_stats']['method']\n",
    "manage_nan = cfg['datamodule']['manage_nan']\n",
    "n_profiles = cfg['datamodule']['n_profiles']\n",
    "\n",
    "\n",
    "date = str(ckpt_path).split(\"/\")[-3]\n",
    "\n",
    "\n",
    "\n",
    "dir_to_relocate = \"/\".join(str(ckpt_path).split(\"/\")[:-2])\n",
    "\n",
    "\n",
    "dest_dir =  f\"{output_path}AE/\" \\\n",
    "            f\"{model_name}/\" \\\n",
    "            f\"channels_{channels_list}/pred_{prediction_weight}_grad_{gradient_weight}/\" \\\n",
    "            f\"{n_conv_per_layer}_conv_per_layer/padding_{padding}/pooling_{pooling}_on_dim_{pooling_dim}/\" \\\n",
    "            f\"final_upsample_{final_upsample_str}/act_fn_{act_fn_str}_final_act_fn_{final_act_fn_str}/\" \\\n",
    "            f\"lr_{lr}/normalization_{normalization_method}/manage_nan_{manage_nan}/n_profiles_{n_profiles}/{date}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/homes/o23gauvr/Documents/thèse/code/FASCINATION/outputs/AE/AE_CNN_3D/channels_[1, 2, 4, 8, 16]/pred_1_grad_100000/1_conv_per_layer/padding_linear/pooling_Max_on_dim_all/final_upsample_upsample_pooling/act_fn_None_final_act_fn_None/lr_0.001/normalization_min_max/manage_nan_suppress/n_profiles_None/2024-10-05_12-16'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in os.listdir(dir_to_relocate):\n",
    "    src = os.path.join(dir_to_relocate, item)\n",
    "    dest = os.path.join(dest_dir, item)\n",
    "    shutil.move(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
