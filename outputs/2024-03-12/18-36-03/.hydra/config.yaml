paths:
  sound: /DATASET/eNATL/eNATL60_BLB002_sound_speed_regrid_0_1000m.nc
normalization:
  x_min: 1459.0439165829073
  x_max: 1545.8698054910844
trainer:
  _target_: pytorch_lightning.Trainer
  inference_mode: false
  accelerator: gpu
  devices: 1
  check_val_every_n_epoch: 1
  logger:
    _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    save_dir: ${hydra:runtime.output_dir}
    name: ${hydra:runtime.choices.xp}
    version: ${model.arch_shape}
    sub_dir: ${model.final_act_func}
  min_epochs: 0
  max_epochs: 1000
  callbacks:
  - _target_: pytorch_lightning.callbacks.LearningRateMonitor
  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: val_loss
    save_top_k: 1
    filename: '{val_loss:.2f}-{epoch:02d}'
    mode: min
datamodule:
  _target_: src.data.AutoEncoderDatamodule
  input_da:
    _target_: src.utils.load_sound_speed_fields
    path: ${paths.sound}
  domains:
    train:
      time:
        _target_: builtins.slice
        _args_:
        - 0
        - 254
    val:
      time:
        _target_: builtins.slice
        _args_:
        - 254
        - 331
    test:
      time:
        _target_: builtins.slice
        _args_:
        - 331
        - 365
  dl_kw:
    batch_size: 4
    num_workers: 4
  x_min: ${normalization.x_min}
  x_max: ${normalization.x_max}
model:
  _target_: src.autoencoder.AutoEncoder
  x_min: ${normalization.x_min}
  x_max: ${normalization.x_max}
  lr: 0.1
  arch_shape: '4_15'
  final_act_func: sigmoid
entrypoints:
- _target_: pytorch_lightning.seed_everything
  seed: 333
- _target_: src.train.base_training
  trainer: ${trainer}
  lit_mod: ${model}
  dm: ${datamodule}
